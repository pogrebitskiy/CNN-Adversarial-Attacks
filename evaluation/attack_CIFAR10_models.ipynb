{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T07:23:19.390811Z",
     "start_time": "2024-04-14T07:23:12.663622Z"
    }
   },
   "source": [
    "from models.CIFAR10_Models import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import utils\n",
    "from art import config\n",
    "from art.utils import load_dataset, get_file\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, ProjectedGradientDescent, DeepFool\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from copy import deepcopy"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dpogrebitskiy/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ff9fdba3e00eaee6",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "BATCH_SIZE = 256\n",
    "EPS = 0.2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "# Define the transformation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
    "\n",
    "# Split the training dataset into training and validation datasets\n",
    "train_dataset, val_dataset = random_split(train_dataset, [50000, 10000], generator=generator)\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "X_train, y_train = utils.loader_to_numpy(train_loader)\n",
    "X_val, y_val = utils.loader_to_numpy(val_loader)\n",
    "X_test, y_test = utils.loader_to_numpy(test_loader)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPS = 0.2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def harden_model(clean_model, clean_classifier, BATCH_SIZE, EPS, adv_model_path, attack_obj, plot_title):\n",
    "    try:\n",
    "        hardened_model = torch.load(adv_model_path)\n",
    "        hardened_classifier = PyTorchClassifier(\n",
    "            model=hardened_model,\n",
    "            loss=torch.nn.CrossEntropyLoss(),\n",
    "            optimizer=torch.optim.Adam(hardened_model.parameters(), lr=0.01),\n",
    "            input_shape=(1, 28, 28),\n",
    "            nb_classes=10,\n",
    "            preprocessing=(0.1307, 0.3081),\n",
    "            device_type='gpu'\n",
    "        )\n",
    "        if isinstance(attack_obj, DeepFool):\n",
    "            attack = attack_obj(hardened_classifier, batch_size=BATCH_SIZE)\n",
    "        else:\n",
    "            attack = attack_obj(hardened_classifier, batch_size=BATCH_SIZE, eps=EPS)\n",
    "    except:\n",
    "        hardened_model = deepcopy(clean_model)\n",
    "        hardened_classifier = PyTorchClassifier(\n",
    "            model=hardened_model,\n",
    "            loss=torch.nn.CrossEntropyLoss(),\n",
    "            optimizer=torch.optim.Adam(hardened_model.parameters(), lr=0.01),\n",
    "            input_shape=(1, 28, 28),\n",
    "            nb_classes=10,\n",
    "            preprocessing=(0.1307, 0.3081),\n",
    "            device_type='gpu'\n",
    "        )\n",
    "        if isinstance(attack_obj, DeepFool):\n",
    "            attack = attack_obj(hardened_classifier, batch_size=BATCH_SIZE)\n",
    "        else:\n",
    "            attack = attack_obj(hardened_classifier, batch_size=BATCH_SIZE, eps=EPS)\n",
    "        adv_trainer = AdversarialTrainer(hardened_classifier, attacks=attack, ratio=0.5)\n",
    "        adv_trainer.fit(X_train, y_train, batch_size=BATCH_SIZE, nb_epochs=10)\n",
    "        torch.save(adv_trainer.classifier.model, adv_model_path)\n",
    "        hardened_classifier = adv_trainer.classifier\n",
    "    \n",
    "    \n",
    "    eps_values = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "    utils.compare_classifiers(clean_classifier, hardened_classifier, X_test, y_test, eps_values, batch_size=BATCH_SIZE, title=plot_title)\n",
    "    \n",
    "    print('Hardened model accuracy on clean test data: ', np.sum(np.argmax(hardened_classifier.predict(X_test), axis=1) == y_test) / len(y_test))\n",
    "    print('Hardened model accuracy on PGD adversarial test data: ', utils.evaluate_attack(attack, hardened_classifier, X_test, y_test))"
   ],
   "id": "ab8921504be3a64d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_adversarial_process(clean_model, BATCH_SIZE, EPS, adv_model_path, plot_title):\n",
    "    clean_classifier = PyTorchClassifier(\n",
    "    model=clean_model,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(clean_model.parameters(), lr=0.01),\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    "    preprocessing=(0.1307, 0.3081),\n",
    "    device_type='gpu'\n",
    ")\n",
    "\n",
    "    # Get the clean accuracy\n",
    "    clean_acc = np.sum(np.argmax(clean_classifier.predict(X_test), axis=1) == y_test) / len(y_test)\n",
    "    print(f'Clean accuracy: {clean_acc}')\n",
    "    \n",
    "    # Try FGSM\n",
    "    attack = FastGradientMethod(clean_classifier, batch_size=BATCH_SIZE, eps=EPS)\n",
    "    print('Accuracy on adversarial test data: ', utils.evaluate_attack(attack, clean_classifier, X_test, y_test))\n",
    "    utils.plot_images(X_test, y_test, clean_classifier, attack, n=5)\n",
    "    \n",
    "    # Try BIM\n",
    "    attack = BasicIterativeMethod(clean_classifier, batch_size=BATCH_SIZE, eps=EPS)\n",
    "    print('Accuracy on adversarial test data: ', utils.evaluate_attack(attack, clean_classifier, X_test, y_test))\n",
    "    utils.plot_images(X_test, y_test, clean_classifier, attack, n=5)\n",
    "    \n",
    "    # Try PGD\n",
    "    attack = ProjectedGradientDescent(clean_classifier, batch_size=BATCH_SIZE, eps=EPS)\n",
    "    print('Accuracy on adversarial test data: ', utils.evaluate_attack(attack, clean_classifier, X_test, y_test))\n",
    "    utils.plot_images(X_test, y_test, clean_classifier, attack, n=5)\n",
    "    \n",
    "    # Try deepfool\n",
    "    attack = DeepFool(clean_classifier, batch_size=BATCH_SIZE)\n",
    "    print('Accuracy on adversarial test data: ', utils.evaluate_attack(attack, clean_classifier, X_test, y_test))\n",
    "    utils.plot_images(X_test, y_test, clean_classifier, attack, n=5)\n",
    "    \n",
    "    # harden with BIM\n",
    "    harden_model(clean_model, clean_classifier, BATCH_SIZE, EPS, adv_model_path, BasicIterativeMethod, plot_title + ' Hardened with BIM')\n",
    "    \n",
    "    # harden with PGD\n",
    "    harden_model(clean_model, clean_classifier, BATCH_SIZE, EPS, adv_model_path, ProjectedGradientDescent, plot_title + ' Hardened with PGD')\n",
    "    \n",
    "    # harden with FGSM\n",
    "    harden_model(clean_model, clean_classifier, BATCH_SIZE, EPS, adv_model_path, FastGradientMethod, plot_title + ' Hardened with FGSM')\n",
    "    \n",
    "    # harden with DeepFool\n",
    "    harden_model(clean_model, clean_classifier, BATCH_SIZE, EPS, adv_model_path, DeepFool, plot_title + ' Hardened with DeepFool')"
   ],
   "id": "589d7921ef6ea9db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load the FC model\n",
    "clean_model = CIFAR10_FC500_100_10()\n",
    "clean_model.load_state_dict(torch.load('models/clean_state/CIFAR10_FC_500_100_10.pth'))\n",
    "clean_model.eval()\n",
    "\n",
    "run_adversarial_process(clean_model, BATCH_SIZE, EPS, 'models/hardened_state/CIFAR10_FC_500_100_10.pth', 'CIFAR10_FC_500_100_10 Adversarial Accuracy')"
   ],
   "id": "c346aa6ae4e4a511"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load the VGG model\n",
    "clean_model = CIFAR10_VGG()\n",
    "clean_model.load_state_dict(torch.load('models/clean_state/CIFAR10_VGG.pth'))\n",
    "clean_model.eval()\n",
    "\n",
    "run_adversarial_process(clean_model, BATCH_SIZE, EPS, 'models/hardened_state/CIFAR10_VGG.pth', 'CIFAR10_VGG Adversarial Accuracy')"
   ],
   "id": "b0e4d8095ebfddc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load the LeNet model\n",
    "clean_model = CIFAR10_LeNet()\n",
    "clean_model.load_state_dict(torch.load('models/clean_state/CIFAR10_LeNet.pth'))\n",
    "clean_model.eval()\n",
    "\n",
    "run_adversarial_process(clean_model, BATCH_SIZE, EPS, 'models/hardened_state/CIFAR10_LeNet.pth', 'CIFAR10_LeNet Adversarial Accuracy')"
   ],
   "id": "fd0fd431d384e0f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load the GoogLeNet model\n",
    "clean_model = CIFAR10_GoogLeNet()\n",
    "clean_model.load_state_dict(torch.load('models/clean_state/CIFAR10_GoogLeNet.pth'))\n",
    "clean_model.eval()\n",
    "\n",
    "run_adversarial_process(clean_model, BATCH_SIZE, EPS, 'models/hardened_state/CIFAR10_GoogLeNet.pth', 'CIFAR10_GoogLeNet Adversarial Accuracy')"
   ],
   "id": "5883d2027aaf625c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load the ResNet model\n",
    "clean_model = CIFAR10_ResNet()\n",
    "clean_model.load_state_dict(torch.load('models/clean_state/CIFAR10_ResNet.pth'))\n",
    "clean_model.eval()\n",
    "\n",
    "run_adversarial_process(clean_model, BATCH_SIZE, EPS, 'models/hardened_state/CIFAR10_ResNet.pth', 'CIFAR10_ResNet Adversarial Accuracy')"
   ],
   "id": "66f728deafd86fbc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
